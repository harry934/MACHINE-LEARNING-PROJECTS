{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkAT6qzjy93lf3UfUCB39T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harry934/MACHINE-LEARNING-PROJECTS/blob/main/Implementing_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clNWTvGkdfqb",
        "outputId": "cf2364aa-318c-4c46-e7e1-92c7e9fb865d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.12/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.14.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->pyLDAvis) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim scikit-learn pandas nltk matplotlib seaborn pyLDAvis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: import libraries"
      ],
      "metadata": {
        "id": "mRva5Jwdh3i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pprint import pprint\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to address the specific LookupError"
      ],
      "metadata": {
        "id": "m_rNLJt7d9UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c496a326-7cf2-4688-f320-3f5caac5ed89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Sample text corpus"
      ],
      "metadata": {
        "id": "0EGEfGWdf436"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        " \"Machine learning is fascinating and useful.\",\n",
        " \"Python is great for data analysis and modeling.\",\n",
        " \"Artificial intelligence includes machine learning.\",\n",
        " \"The political elite are in desperation. Ordinary kalenjins are suspicious of kikuyu community\",\n",
        " \"Am just curious the only people who are calling him old and mad are Kikuyus and not Kalenjins and that's a good sign USERNAME_1 USERNAME_2\",\n",
        " \"War expected in Nakuru if something is not done . All Luos given Seven days to leave. Why are Kenyans Killing...\"\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "BK5uQDzZfEDD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Text preprocessing"
      ],
      "metadata": {
        "id": "zoKcsnMZf3Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "texts = [[word for word in word_tokenize(doc.lower()) if word.isalpha() and\n",
        "word not in stop_words]\n",
        " for doc in documents]\n"
      ],
      "metadata": {
        "id": "Z8ezFChDfWjM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Create Dictionary and Corpus"
      ],
      "metadata": {
        "id": "tSRSUCvrgmQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n"
      ],
      "metadata": {
        "id": "VqM6hbOif0b0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Train LDA model"
      ],
      "metadata": {
        "id": "08Ub0CKOhs2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaModel(corpus=corpus,\n",
        " id2word=dictionary,\n",
        "num_topics=2,\n",
        "random_state=42,\n",
        "passes=10)\n"
      ],
      "metadata": {
        "id": "B-oNv3qyhpe8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda_model.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZvgN90jAsu",
        "outputId": "e830e93e-dc6e-42ea-d18e-7a6acf280420"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.033*\"calling\" + 0.033*\"people\" + 0.033*\"mad\" + 0.033*\"old\" + 0.033*\"kikuyus\" + 0.033*\"sign\" + 0.033*\"curious\" + 0.033*\"good\" + 0.033*\"luos\" + 0.033*\"something\"'), (1, '0.067*\"learning\" + 0.067*\"machine\" + 0.041*\"kalenjins\" + 0.040*\"suspicious\" + 0.040*\"elite\" + 0.040*\"desperation\" + 0.040*\"political\" + 0.040*\"ordinary\" + 0.040*\"kikuyu\" + 0.040*\"community\"')]\n"
          ]
        }
      ]
    }
  ]
}